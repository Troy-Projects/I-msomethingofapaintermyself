{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":21755,"databundleVersionId":1475600,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Project topic & generative DL\nThis project translates natural photos into Monet-style images. Generative deep learning—specifically GANs—pits a generator that synthesizes images against a discriminator that distinguishes real from fake, improving image realism through adversarial training.\n\nData (size, dimension, structure)\nThe dataset contains 300 Monet paintings and about 7,038 photos. All images are RGB with varying widths and heights; I standardize everything to 256×256 for training and inference.\n\nEDA (visuals)\nI show a 3×3 grid of Monet samples and a 3×3 grid of Photo samples to visualize style differences. I include pixel-intensity histograms to compare tonal distributions. Optionally, I add width/height histograms and a quick duplicate check to confirm data quality.\n\nData cleaning / preprocessing\nAll images are resized to 256×256; for GAN training I normalize to [-1, 1] and use simple augmentations such as horizontal flips and random crops. This stabilizes training and matches common baselines.\n\nPlan of analysis\nI begin with a fast color-transfer baseline to guarantee a valid submission, then outline a CycleGAN approach that uses cycle-consistency and identity losses with a PatchGAN discriminator. MiFID is the evaluation metric reported on the leaderboard.\n\nModel architecture & tuning\nThe planned GAN uses a ResNet-9 (or U-Net) generator and a 70×70 PatchGAN discriminator. I vary λ_cycle, λ_identity, learning rate, β1, batch size, and training steps. I compare the baseline to the CycleGAN plan (or a partial training run) to show the effect of architecture and hyperparameters.\n\nResults & analysis\nI include a grid of generated outputs to assess visual quality. I report the Kaggle MiFID (public leaderboard score) and describe what helped or hurt performance along with any tuning I tried.\n\nConclusion\nI restate the best result, summarize key learnings, explain what did not work and why, and list concrete next steps to improve the model.\n\nRepo & submission\nI provide a public GitHub repository with the notebook and a concise README explaining how to reproduce results, and I include a screenshot of my Kaggle leaderboard entry.","metadata":{}},{"cell_type":"code","source":"# ONE-CELL SUBMISSION MAKER (\nfrom pathlib import Path\nimport numpy as np, zipfile\nfrom PIL import Image\nimport os\n\n# 1) locate data\nROOT = Path(\"/kaggle/input/gan-getting-started\")\nMONET_DIR = ROOT/\"monet_jpg\"\nPHOTO_DIR = ROOT/\"photo_jpg\"\nmonet_paths = sorted(MONET_DIR.glob(\"*.jpg\"))\nphoto_paths = sorted(PHOTO_DIR.glob(\"*.jpg\"))\nprint(\"Counts -> Monet:\", len(monet_paths), \"Photos:\", len(photo_paths))\n\n# 2) fast baseline \ndef monetize_baseline(photo_img, ref_img):\n    p = np.asarray(photo_img.convert(\"RGB\").resize((256,256))).astype(np.float32)\n    r = np.asarray(ref_img.convert(\"RGB\").resize((256,256))).astype(np.float32)\n    p_m, p_s = p.mean((0,1), keepdims=True), p.std((0,1), keepdims=True)+1e-6\n    r_m, r_s = r.mean((0,1), keepdims=True), r.std((0,1), keepdims=True)+1e-6\n    out = (p - p_m) / p_s * r_s + r_m\n    return Image.fromarray(np.clip(out,0,255).astype(np.uint8))\n\n# 3) generate 7000 JPGs and zip them\nout_dir = Path(\"/kaggle/working/images\"); out_dir.mkdir(exist_ok=True)\nfor f in out_dir.glob(\"*\"): f.unlink()  # clean any old files\n\nrng = np.random.default_rng(42)\nrefs = rng.choice(monet_paths, min(50, len(monet_paths)), replace=False)\nsel  = rng.choice(photo_paths, min(7000, len(photo_paths)), replace=False)\n\nfor i, p in enumerate(sel, 1):\n    im  = Image.open(p)\n    ref = Image.open(rng.choice(refs))\n    monetize_baseline(im, ref).save(out_dir/f\"image_{i:05d}.jpg\", \"JPEG\", quality=92)\n    if i % 500 == 0: print(f\"{i}/{len(sel)}\")\n\nzip_path = \"/kaggle/working/images.zip\"=-\nwith zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as z:\n    for f in out_dir.glob(\"*.jpg\"):\n        z.write(f, f.name)\n\nprint(\"Ready to submit:\", zip_path, \"| count:\", len(list(out_dir.glob('*.jpg'))))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T20:06:48.874167Z","iopub.execute_input":"2025-08-26T20:06:48.874496Z","iopub.status.idle":"2025-08-26T20:08:52.864215Z","shell.execute_reply.started":"2025-08-26T20:06:48.874476Z","shell.execute_reply":"2025-08-26T20:08:52.862967Z"}},"outputs":[{"name":"stdout","text":"Counts -> Monet: 300 Photos: 7038\n500/7000\n1000/7000\n1500/7000\n2000/7000\n2500/7000\n3000/7000\n3500/7000\n4000/7000\n4500/7000\n5000/7000\n5500/7000\n6000/7000\n6500/7000\n7000/7000\nReady to submit: /kaggle/working/images.zip | count: 7000\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"# FAST generator (keeps Save & Run All quick and stable)\nfrom PIL import Image\nimport numpy as np\n\ndef monetize_baseline(photo_img, ref_img):\n    p = np.asarray(photo_img.convert(\"RGB\").resize((256,256))).astype(np.float32)\n    r = np.asarray(ref_img.convert(\"RGB\").resize((256,256))).astype(np.float32)\n    p_m, p_s = p.mean((0,1), keepdims=True), p.std((0,1), keepdims=True)+1e-6\n    r_m, r_s = r.mean((0,1), keepdims=True), r.std((0,1), keepdims=True)+1e-6\n    out = (p - p_m) / p_s * r_s + r_m\n    return Image.fromarray(np.clip(out,0,255).astype(np.uint8))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T01:34:10.001842Z","iopub.execute_input":"2025-08-27T01:34:10.002452Z","iopub.status.idle":"2025-08-27T01:34:10.011432Z","shell.execute_reply.started":"2025-08-27T01:34:10.002413Z","shell.execute_reply":"2025-08-27T01:34:10.010238Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from pathlib import Path\nimport zipfile\nfrom IPython.display import FileLink\n\nout_dir = Path(\"/kaggle/working/images\")\nzip_path = Path(\"/kaggle/working/images.zip\")\n\n# If the zip doesn't exist yet, create it from the JPGs you see in /kaggle/working/images\nif not zip_path.exists():\n    with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as z:\n        for f in out_dir.glob(\"*.jpg\"):\n            z.write(f, f.name)\n\nprint(\"zip exists:\", zip_path.exists(), \"files:\", len(list(out_dir.glob('*.jpg'))))\nFileLink(str(zip_path))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pathlib import Path\nimport numpy as np, zipfile\nfrom PIL import Image\n\n# assumes monet_paths, photo_paths, monetize_baseline() already defined\nout_dir = Path(\"/kaggle/working/images\"); out_dir.mkdir(exist_ok=True)\n# clean old outputs (PNGs, etc.)\nfor f in out_dir.glob(\"*.*\"):\n    f.unlink()\n\nN = min(7000, len(photo_paths))          # 7k fits the 7k–10k rule\nsel = np.random.choice(photo_paths, N, replace=False)\nref_pool = np.random.choice(monet_paths, min(50, len(monet_paths)), replace=False)\n\nfor i, p in enumerate(sel, 1):\n    photo = Image.open(p)\n    ref   = Image.open(np.random.choice(ref_pool))\n    out   = monetize_baseline(photo, ref).resize((256,256)).convert(\"RGB\")\n    out.save(out_dir / f\"image_{i:05d}.jpg\", \"JPEG\", quality=92)\n    if i % 500 == 0: print(f\"{i}/{N} generated\")\n\nzip_path = \"/kaggle/working/images.zip\"\nwith zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as z:\n    for f in out_dir.glob(\"*.jpg\"):\n        z.write(f, arcname=f.name)\n\nprint(\"Ready to submit:\", zip_path, \"| count:\", len(list(out_dir.glob('*.jpg'))))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T20:03:42.621211Z","iopub.execute_input":"2025-08-26T20:03:42.621530Z","iopub.status.idle":"2025-08-26T20:05:48.784512Z","shell.execute_reply.started":"2025-08-26T20:03:42.621508Z","shell.execute_reply":"2025-08-26T20:05:48.783544Z"}},"outputs":[{"name":"stdout","text":"500/7000 generated\n1000/7000 generated\n1500/7000 generated\n2000/7000 generated\n2500/7000 generated\n3000/7000 generated\n3500/7000 generated\n4000/7000 generated\n4500/7000 generated\n5000/7000 generated\n5500/7000 generated\n6000/7000 generated\n6500/7000 generated\n7000/7000 generated\nReady to submit: /kaggle/working/images.zip | count: 7000\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ngen_paths = sorted((Path(\"/kaggle/working/images\")).glob(\"*.jpg\"))[:9]\nplt.figure(figsize=(6,6))\nfor i,p in enumerate(gen_paths,1):\n    plt.subplot(3,3,i); plt.imshow(Image.open(p)); plt.axis(\"off\")\nplt.suptitle(\"Generated Monet-style samples\"); plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T19:28:13.041495Z","iopub.execute_input":"2025-08-26T19:28:13.041770Z","iopub.status.idle":"2025-08-26T19:28:13.476448Z","shell.execute_reply.started":"2025-08-26T19:28:13.041748Z","shell.execute_reply":"2025-08-26T19:28:13.475636Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Data: Monet_jpg (≈7k paintings), Photo_jpg (≈7k photos), Test_jpg (≈3k photos).\nImages are RGB; we’ll standardize to 256×256 for training/inference.\n","metadata":{"execution":{"iopub.status.busy":"2025-08-26T18:41:10.072295Z","iopub.execute_input":"2025-08-26T18:41:10.072659Z","iopub.status.idle":"2025-08-26T18:41:10.079962Z","shell.execute_reply.started":"2025-08-26T18:41:10.072636Z","shell.execute_reply":"2025-08-26T18:41:10.078746Z"}}},{"cell_type":"code","source":"def show_grid(paths, title):\n    idx = np.random.choice(len(paths), 9, replace=False)\n    plt.figure(figsize=(6,6))\n    for i,j in enumerate(idx,1):\n        plt.subplot(3,3,i)\n        plt.imshow(Image.open(paths[j]))\n        plt.axis(\"off\")\n    plt.suptitle(title); plt.show()\n\nshow_grid(monet_paths, \"Monet samples\")\nshow_grid(photo_paths, \"Photo samples\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T19:28:13.477248Z","iopub.execute_input":"2025-08-26T19:28:13.477466Z","iopub.status.idle":"2025-08-26T19:28:14.414403Z","shell.execute_reply.started":"2025-08-26T19:28:13.477447Z","shell.execute_reply":"2025-08-26T19:28:14.412998Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def intensity_hist(paths, n=200):\n    vals = []\n    for p in np.random.choice(paths, min(n, len(paths)), replace=False):\n        arr = np.asarray(Image.open(p).convert(\"L\").resize((256,256)))\n        vals.append(arr.flatten())\n    vals = np.concatenate(vals)\n    plt.hist(vals, bins=30)\n    plt.title(\"Pixel intensity distribution\"); plt.xlabel(\"0..255\"); plt.ylabel(\"count\")\n    plt.show()\n\nintensity_hist(monet_paths)\nintensity_hist(photo_paths)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T19:28:14.415338Z","iopub.execute_input":"2025-08-26T19:28:14.415624Z","iopub.status.idle":"2025-08-26T19:28:16.075514Z","shell.execute_reply.started":"2025-08-26T19:28:14.415596Z","shell.execute_reply":"2025-08-26T19:28:16.074671Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Plan: Start with a fast baseline (histogram-matching color transfer) to guarantee a valid submission. \nThen, if time allows, train a lightweight CycleGAN (ResNet-9 generator + 70×70 PatchGAN) with λ_cycle=10, λ_id=5, lr=2e-4, β1=0.5, batch=1–4, a few epochs.\nEvaluation: Kaggle MiFID; we show qualitative grids and report public score.\n","metadata":{"execution":{"iopub.status.busy":"2025-08-26T18:44:10.805136Z","iopub.execute_input":"2025-08-26T18:44:10.805355Z","iopub.status.idle":"2025-08-26T18:44:10.812274Z","shell.execute_reply.started":"2025-08-26T18:44:10.805337Z","shell.execute_reply":"2025-08-26T18:44:10.811124Z"}}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Try to use scikit-image; if unavailable, fall back to simple channel-wise mean/std transfer\ntry:\n    from skimage.exposure import match_histograms\n    def monetize_baseline(photo_img: Image.Image, ref_img: Image.Image) -> Image.Image:\n        photo = photo_img.convert(\"RGB\").resize((256,256))\n        ref   = ref_img.convert(\"RGB\").resize((256,256))\n        matched = match_histograms(np.asarray(photo), np.asarray(ref), channel_axis=-1)\n        return Image.fromarray(np.clip(matched,0,255).astype(np.uint8))\nexcept Exception:\n    def monetize_baseline(photo_img: Image.Image, ref_img: Image.Image) -> Image.Image:\n        p = np.asarray(photo_img.convert(\"RGB\").resize((256,256))).astype(np.float32)\n        r = np.asarray(ref_img.convert(\"RGB\").resize((256,256))).astype(np.float32)\n        p_m, p_s = p.mean((0,1), keepdims=True), p.std((0,1), keepdims=True)+1e-6\n        r_m, r_s = r.mean((0,1), keepdims=True), r.std((0,1), keepdims=True)+1e-6\n        out = (p - p_m) / p_s * r_s + r_m\n        return Image.fromarray(np.clip(out,0,255).astype(np.uint8))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T19:28:16.077077Z","iopub.execute_input":"2025-08-26T19:28:16.077343Z","iopub.status.idle":"2025-08-26T19:28:16.086222Z","shell.execute_reply.started":"2025-08-26T19:28:16.077324Z","shell.execute_reply":"2025-08-26T19:28:16.084368Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"out_dir = Path(\"/kaggle/working/images\"); out_dir.mkdir(exist_ok=True)\nref_pool = np.random.choice(monet_paths, min(50, len(monet_paths)), replace=False)\n\nfor i, p in enumerate(test_paths, 1):\n    photo = Image.open(p)\n    ref   = Image.open(np.random.choice(ref_pool))\n    out   = monetize_baseline(photo, ref)\n    out.save(out_dir / (p.stem + \".png\"))\n    if i % 300 == 0: print(f\"{i}/{len(test_paths)}\")\n\nzip_path = \"/kaggle/working/images.zip\"\nwith zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as z:\n    for f in out_dir.glob(\"*.png\"):\n        z.write(f, arcname=f.name)\n\nprint(\"Ready to submit:\", zip_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T19:28:16.087081Z","iopub.execute_input":"2025-08-26T19:28:16.087371Z","iopub.status.idle":"2025-08-26T19:28:16.681769Z","shell.execute_reply.started":"2025-08-26T19:28:16.087342Z","shell.execute_reply":"2025-08-26T19:28:16.680732Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"CycleGAN plan:\n- Generators: ResNet-9 (photo→Monet, Monet→photo) with InstanceNorm; 256×256 inputs; residual blocks in the bottleneck.\n- Discriminators: 70×70 PatchGAN.\n- Loss: L_adv (LSGAN), L_cycle (λ=10), L_identity (λ=5).\n- Optimizer: Adam(lr=2e-4, β1=0.5). Batch size=1–4. Train for N steps/epochs with image flips/crops.\nWe will compare LR/λ settings and report CV proxy losses + qualitative grids; public MiFID used for final comparison.\n","metadata":{"execution":{"iopub.status.busy":"2025-08-26T18:44:41.385218Z","iopub.execute_input":"2025-08-26T18:44:41.385525Z","iopub.status.idle":"2025-08-26T18:44:41.405612Z","shell.execute_reply.started":"2025-08-26T18:44:41.385490Z","shell.execute_reply":"2025-08-26T18:44:41.404334Z"}}},{"cell_type":"markdown","source":"Plan of analysis: Start with this fast color-transfer baseline to ensure a valid MiFID submission. \nExtension plan: CycleGAN with ResNet-9 generators and 70×70 PatchGAN discriminators; losses = adversarial + cycle (λ=10) + identity (λ=5); Adam lr=2e-4, β1=0.5, batch 1–4.\n","metadata":{"execution":{"iopub.status.busy":"2025-08-26T18:46:09.122470Z","iopub.execute_input":"2025-08-26T18:46:09.122787Z","iopub.status.idle":"2025-08-26T18:46:09.149458Z","shell.execute_reply.started":"2025-08-26T18:46:09.122760Z","shell.execute_reply":"2025-08-26T18:46:09.148257Z"}}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}